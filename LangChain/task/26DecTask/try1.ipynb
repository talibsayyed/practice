{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date and Time (UTC): 2024-12-27 11:08:59\n",
      "\n",
      "Reading input file: partnumsample.txt\n",
      "Total products to process: 460\n",
      "\n",
      "Processing chunk 1...\n",
      "\n",
      "Processing chunk 2...\n",
      "\n",
      "Processing chunk 3...\n",
      "\n",
      "Processing chunk 4...\n",
      "\n",
      "Processing chunk 5...\n",
      "\n",
      "Processing chunk 6...\n",
      "\n",
      "Processing chunk 7...\n",
      "\n",
      "Processing chunk 8...\n",
      "\n",
      "Processing chunk 9...\n",
      "\n",
      "Processing chunk 10...\n",
      "\n",
      "Processing chunk 11...\n",
      "\n",
      "Processing chunk 12...\n",
      "\n",
      "Processing chunk 13...\n",
      "\n",
      "Processing chunk 14...\n",
      "\n",
      "Processing chunk 15...\n",
      "\n",
      "Processing chunk 16...\n",
      "\n",
      "Processing chunk 17...\n",
      "\n",
      "Processing chunk 18...\n",
      "\n",
      "Processing chunk 19...\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Processing complete!\n",
      "Total results processed: 75\n",
      "Results have been saved to 'analysis_results.json'\n",
      "\n",
      "Example of first few results:\n",
      "{\n",
      "  \"Description\": \"107-C / 607 1-1/4 WROT CXC 90 ELL Pn: 5817\",\n",
      "  \"Product Code\": \"5817\",\n",
      "  \"Category Name\": \"PN numeric suffix\"\n",
      "}\n",
      "{\n",
      "  \"Description\": \"B-T05LF 1 LEAD FREE BRASS TEE Pn: 722192\",\n",
      "  \"Product Code\": \"722192\",\n",
      "  \"Category Name\": \"PN numeric suffix\"\n",
      "}\n",
      "{\n",
      "  \"Description\": \"BWC RG1PV50S6N19 TTW 50 GALLON RESIDENTIAL GAS (NATURAL) POWER VENT WATER HEATER ** Original Sale : S4579739.001 ** ** Cus PO: STOCK ** DENTED / CONCEALED DAMAGE Pn: 1355485\",\n",
      "  \"Product Code\": \"1355485\",\n",
      "  \"Category Name\": \"PN numeric suffix\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "# Set your API key here\n",
    "api_key = \"sk-svcacct-WqOWrSDc4rSGBDG7-QcN4cZqh6SiGuIEPb44EL3_nhxAaoeeMpOhTLbbhA8CrwT3BlbkFJ1RwNoTMV9rjb57Ir5WtfPhMB54f7MKYGjaPgLdsPAHTplF-u-6m3Gb0R-_3-0A\"  # Replace with your actual OpenAI API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def read_input_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            content = file.read()\n",
    "            if not content.strip().startswith('{'):\n",
    "                content = '{' + content\n",
    "            if not content.strip().endswith('}'):\n",
    "                content = content + '}'\n",
    "            return json.loads(content)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format in file: {e}\")\n",
    "        return None\n",
    "\n",
    "def chunk_data(products, chunk_size=50):\n",
    "    \"\"\"Split the products into smaller chunks\"\"\"\n",
    "    for i in range(0, len(products), chunk_size):\n",
    "        yield products[i:i + chunk_size]\n",
    "\n",
    "def process_chunk(chunk_data):\n",
    "    # Convert the chunk to a string format for the prompt\n",
    "    data_str = json.dumps({\"ListOfProducts\": chunk_data}, indent=2)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that analyzes product descriptions and extracts product codes.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Your task is to analyze each description and categorize it based on the **position** and **pattern** of the product code in the description.\n",
    "\n",
    "### Task Details:\n",
    "1. **Identify and Extract Product Code**:  \n",
    "   - Identify the product code in each description. Typically, this appears with a prefix like `Pn:` or has a distinct pattern (e.g., alphanumeric sequences or separated by special characters).\n",
    "\n",
    "2. **Categorize Descriptions**:  \n",
    "   - Create a category for each description based on:\n",
    "     - The **position** of the product code (e.g., at the end, middle, or beginning).\n",
    "     - The **pattern** of the product code (e.g., numeric, alphanumeric, prefixed).\n",
    "     - The **position** of the PN code like where is it present suffix or prefix or middle.\n",
    "     - if the pn is numeric and at the end of the description then the category name should be \"PN numeric suffix\" and if the pn is alphanumeric and at the end of the description then the category name should be \"PN alphanumeric suffix\" and if the pn is numeric and at the beginning of the description then the category name should be \"PN numeric prefix\" and if the pn is alphanumeric and at the beginning of the description then the category name should be \"PN alphanumeric prefix\" and if the pn is numeric and in the middle of the description then the category name should be \"PN numeric middle\" and if the pn is alphanumeric and in the middle of the description then the category name should be \"PN alphanumeric middle\"\n",
    "         \n",
    "\n",
    "Input Data:\n",
    "{data_str}\n",
    "\n",
    "Please provide the results in this JSON structure:\n",
    "{{\n",
    "    \"results\": [\n",
    "        {{\"Description\": \"\", \"Product Code\": \"\", \"Category Name\": \"\"}},\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Focus on:\n",
    "1. Extracting product codes (especially after \"Pn:\" or unique identifiers)\n",
    "2. Categorizing based on code format and position\n",
    "3. Maintaining the exact format specified above\n",
    "\"\"\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return None\n",
    "\n",
    "def merge_results(results_list):\n",
    "    \"\"\"Merge all chunk results into a single JSON structure\"\"\"\n",
    "    all_results = []\n",
    "    for result in results_list:\n",
    "        try:\n",
    "            if result:\n",
    "                # Parse the JSON string\n",
    "                result_dict = json.loads(result)\n",
    "                if \"results\" in result_dict:\n",
    "                    all_results.extend(result_dict[\"results\"])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing result: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return {\"results\": all_results}\n",
    "\n",
    "# Main execution\n",
    "print(f\"Current Date and Time (UTC): {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "input_file = \"partnumsample.txt\"\n",
    "print(f\"\\nReading input file: {input_file}\")\n",
    "\n",
    "# Read the data\n",
    "input_data = read_input_file(input_file)\n",
    "if input_data and \"ListOfProducts\" in input_data:\n",
    "    products = input_data[\"ListOfProducts\"]\n",
    "    print(f\"Total products to process: {len(products)}\")\n",
    "    \n",
    "    # Process in chunks\n",
    "    all_results = []\n",
    "    for i, chunk in enumerate(chunk_data(products, chunk_size=25)):\n",
    "        print(f\"\\nProcessing chunk {i+1}...\")\n",
    "        result = process_chunk(chunk)\n",
    "        if result:\n",
    "            all_results.append(result)\n",
    "    \n",
    "    # Merge all results\n",
    "    if all_results:\n",
    "        final_results = merge_results(all_results)\n",
    "        \n",
    "        # Save results\n",
    "        with open(\"analysis_results.json\", \"w\") as f:\n",
    "            json.dump(final_results, f, indent=2)\n",
    "        \n",
    "        print(\"\\nProcessing complete!\")\n",
    "        print(f\"Total results processed: {len(final_results['results'])}\")\n",
    "        print(\"Results have been saved to 'analysis_results.json'\")\n",
    "        \n",
    "        # Display first few results as example\n",
    "        print(\"\\nExample of first few results:\")\n",
    "        for item in final_results['results'][:3]:\n",
    "            print(json.dumps(item, indent=2))\n",
    "else:\n",
    "    print(\"No valid data to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
