{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with LangChain and OpenAI\n",
    "\n",
    "1. Get setup with LangChain, LangSmith and LangServe\n",
    "2. Use the most basic and common components of LangChain: prompt templates, models and output parsers.\n",
    "3. Build a Simple application with LangChain.\n",
    "4. Trace our application with LangSmith.\n",
    "5. Serve our application with LangServe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000001E4559F8690> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001E455A04590> root_client=<openai.OpenAI object at 0x000001E45505B290> root_async_client=<openai.AsyncOpenAI object at 0x000001E4558E0610> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model='gpt-4o')\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a category of artificial intelligence systems designed to generate new content, such as images, text, music, or other data, that resembles the input data they were trained on. These systems use machine learning models, especially deep learning techniques, to identify patterns and structures in existing data and then create novel outputs that adhere to those patterns.\\n\\nKey types of generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** Comprising two neural networks—a generator and a discriminator—GANs are trained in a competitive setting. The generator creates new data instances, while the discriminator evaluates them against real data, guiding the generator to produce increasingly realistic outputs.\\n\\n2. **Variational Autoencoders (VAEs):** These models encode input data into a compressed latent space and then decode it back to its original form, with the added ability to generate new, similar data by sampling from the latent space.\\n\\n3. **Transformer-based Models:** Models like GPT (Generative Pre-trained Transformer) leverage transformers to generate coherent and contextually relevant text by predicting the next word in a sequence, given preceding words.\\n\\nGenerative AI has a wide range of applications, including content creation for entertainment, art, and design, improving medical imaging, enhancing virtual reality experiences, and even drug discovery. Its ability to autonomously create realistic and customized content is transforming industries, though it also raises ethical concerns around misinformation, copyright, and data privacy.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 292, 'prompt_tokens': 12, 'total_tokens': 304, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'stop', 'logprobs': None}, id='run-d45e9847-ce56-42a7-9755-c136541bd135-0', usage_metadata={'input_tokens': 12, 'output_tokens': 292, 'total_tokens': 304, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is Generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Youre an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"Youre an expert AI Engineer. Provide me answers based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a tool developed by LangChain designed to facilitate the development and debugging of applications that utilize language models. It provides a suite of features that enhance the process of building, testing, and optimizing applications driven by natural language processing. Key features include observability for tracking application performance, tools for evaluating and debugging language model outputs, and experiment tracking to compare different versions of models or prompts. This makes Langsmith particularly useful for developers and researchers working to refine and improve the functionality of language model-based systems.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 33, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None} id='run-f00811f0-35f5-4843-80c7-5d3045887f4d-0' usage_metadata={'input_tokens': 33, 'output_tokens': 102, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Chain \n",
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform developed by LangChain, designed to enhance the process of building, debugging, and monitoring applications that utilize large language models (LLMs). It provides a suite of tools aimed at improving the developer experience when working with LLMs, focusing on aspects like evaluation, testing, and tracing. By offering these features, LangSmith helps developers ensure that their applications are functioning as intended, optimize performance, and quickly identify and resolve issues. This platform is particularly useful for those working on complex language-based applications who need a robust environment to manage and refine their models effectively.\n"
     ]
    }
   ],
   "source": [
    "## String output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
