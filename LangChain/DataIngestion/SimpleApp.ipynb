{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Gen AI app using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Data ingestion-- from the website we need to scrape the data \n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x27f81e8f4d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nOptimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringTutorialsOptimize a classifierOn this pageOptimize a classifier\\nThis tutorial walks through optimizing a classifier based on user a feedback.\\nClassifiers are great to optimize because its generally pretty simple to collect the desired output, which makes it easy to create few shot examples based on user feedback.\\nThat is exactly what we will do in this example.\\nThe objectiveâ€‹\\nIn this example, we will build a bot that classify GitHub issues based on their title.\\nIt will take in a title and classify it into one of many different classes.\\nThen, we will start to collect user feedback and use that to shape how this classifier performs.\\nGetting startedâ€‹\\nTo get started, we will first set it up so that we send all traces to a specific project.\\nWe can do this by setting an environment variable:\\nimport osos.environ[\"LANGCHAIN_PROJECT\"] = \"classifier\"\\nWe can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.\\nimport openaifrom langsmith import traceable, Clientimport uuidclient = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Issue: {text}\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                )            }        ],    ).choices[0].message.content\\nWe can then start to interact with it.\\nWhen interacting with it, we will generate the LangSmith run id ahead of time and pass that into this function.\\nWe do this so we can attach feedback later on.\\nHere\\'s how we can invoke the application:\\nrun_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})\\nHere\\'s how we can attach feedback after.\\nWe can collect feedback in two forms.\\nFirst, we can collect \"positive\" feedback - this is for examples that the model got right.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"user-score\",    score=1.0,)\\nNext, we can focus on collecting feedback that corresponds to a \"correction\" to the generation.\\nIn this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automationsâ€‹\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.\\n\\nThe second will take all runs with a correction and use a webhook to add them to a dataset.\\nWhen creating this webhook, we will select the option to \"Use Corrections\".\\nThis option will make it so that when creating a dataset from a run, rather than using the output of the run\\nas the gold-truth output of the datapoint, it will use the correction.\\n\\nUpdate the applicationâ€‹\\nWe can now update our code to pull down the dataset we are sending runs to.\\nOnce we pull it down, we can create a string with the examples in it.\\nWe can then put this string as part of the prompt!\\n### NEW CODE #### Initialize the LangSmith Client so we can use to get the datasetls_client = Client()# Create a function that will take in a list of examples and format them into a stringdef create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)### NEW CODE ###client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    # We can now pull down the examples from the dataset    # We do this inside the function so it always get the most up-to-date examples,    # But this can be done outside and cached for speed if desired    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))  # <- New Code    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.content\\nIf now run the application with a similar input as before, we can see that it correctly learns that anything related to docs (even if a bug) should be classified as documentation\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"address bug in documentation\",    langsmith_extra={\"run_id\": run_id})\\nSemantic search over examplesâ€‹\\nOne additional thing we can do is only use the most semantically similar examples.\\nThis is useful when you start to build up a lot of examples.\\nIn order to do this, we can first define an example to find the k most similar examples:\\nimport numpy as npdef find_similar(examples, topic, k=5):    inputs = [e.inputs[\\'topic\\'] for e in examples] + [topic]    vectors = client.embeddings.create(input=inputs, model=\"text-embedding-3-small\")    vectors = [e.embedding for e in vectors.data]    vectors = np.array(vectors)    args = np.argsort(-vectors.dot(vectors[-1])[:-1])[:5]    examples = [examples[i] for i in args]    return examples\\nWe can then use that in the application\\nls_client = Client()def create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))    examples = find_similar(examples, topic)    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.contentWas this page helpful?You can leave detailed feedback on GitHub.PreviousPrompt engineering tutorialsNextPrompt engineering how-to guidesThe objectiveGetting startedSet up automationsUpdate the applicationSemantic search over examplesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringTutorialsOptimize a classifierOn this pageOptimize a classifier\\nThis tutorial walks through optimizing a classifier based on user a feedback.\\nClassifiers are great to optimize because its generally pretty simple to collect the desired output, which makes it easy to create few shot examples based on user feedback.\\nThat is exactly what we will do in this example.\\nThe objectiveâ€‹\\nIn this example, we will build a bot that classify GitHub issues based on their title.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='That is exactly what we will do in this example.\\nThe objectiveâ€‹\\nIn this example, we will build a bot that classify GitHub issues based on their title.\\nIt will take in a title and classify it into one of many different classes.\\nThen, we will start to collect user feedback and use that to shape how this classifier performs.\\nGetting startedâ€‹\\nTo get started, we will first set it up so that we send all traces to a specific project.\\nWe can do this by setting an environment variable:\\nimport osos.environ[\"LANGCHAIN_PROJECT\"] = \"classifier\"\\nWe can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.\\nimport openaifrom langsmith import traceable, Clientimport uuidclient = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Issue: {text}\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                )            }        ],    ).choices[0].message.content\\nWe can then start to interact with it.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then start to interact with it.\\nWhen interacting with it, we will generate the LangSmith run id ahead of time and pass that into this function.\\nWe do this so we can attach feedback later on.\\nHere\\'s how we can invoke the application:\\nrun_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})\\nHere\\'s how we can attach feedback after.\\nWe can collect feedback in two forms.\\nFirst, we can collect \"positive\" feedback - this is for examples that the model got right.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"user-score\",    score=1.0,)\\nNext, we can focus on collecting feedback that corresponds to a \"correction\" to the generation.\\nIn this example the model will classify it as a bug, whereas I really want this to be classified as documentation.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='In this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automationsâ€‹\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='The second will take all runs with a correction and use a webhook to add them to a dataset.\\nWhen creating this webhook, we will select the option to \"Use Corrections\".\\nThis option will make it so that when creating a dataset from a run, rather than using the output of the run\\nas the gold-truth output of the datapoint, it will use the correction.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='Update the applicationâ€‹\\nWe can now update our code to pull down the dataset we are sending runs to.\\nOnce we pull it down, we can create a string with the examples in it.\\nWe can then put this string as part of the prompt!'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='### NEW CODE #### Initialize the LangSmith Client so we can use to get the datasetls_client = Client()# Create a function that will take in a list of examples and format them into a stringdef create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)### NEW CODE ###client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    # We can now pull down the examples from the dataset    # We do this inside the function so it always get the most up-to-date examples,    # But this can be done outside and cached for speed if desired    examples ='),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='down the examples from the dataset    # We do this inside the function so it always get the most up-to-date examples,    # But this can be done outside and cached for speed if desired    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))  # <- New Code    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.content'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='If now run the application with a similar input as before, we can see that it correctly learns that anything related to docs (even if a bug) should be classified as documentation\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"address bug in documentation\",    langsmith_extra={\"run_id\": run_id})\\nSemantic search over examplesâ€‹\\nOne additional thing we can do is only use the most semantically similar examples.\\nThis is useful when you start to build up a lot of examples.\\nIn order to do this, we can first define an example to find the k most similar examples:\\nimport numpy as npdef find_similar(examples, topic, k=5):    inputs = [e.inputs[\\'topic\\'] for e in examples] + [topic]    vectors = client.embeddings.create(input=inputs, model=\"text-embedding-3-small\")    vectors = [e.embedding for e in vectors.data]    vectors = np.array(vectors)    args = np.argsort(-vectors.dot(vectors[-1])[:-1])[:5]    examples = [examples[i] for i in args]    return examples'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then use that in the application'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='ls_client = Client()def create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))    examples = find_similar(examples, topic)    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format('),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.contentWas this page helpful?You can leave detailed feedback on GitHub.PreviousPrompt engineering tutorialsNextPrompt engineering how-to guidesThe objectiveGetting startedSet up automationsUpdate the applicationSemantic search over examplesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## divide text into chunks \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=splitter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb=FAISS.from_documents(documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x27f8141e850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automationsâ€‹\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query from  a vector store db\n",
    "query=\"We can now set up automations to move examples with feedback of some\"\n",
    "result=vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following questions based only on the provided context:\\n<context>\\n{context}\\n</context>\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000027FBF7B5B50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000027FBF79E910>, root_client=<openai.OpenAI object at 0x0000027FBF548B90>, root_async_client=<openai.AsyncOpenAI object at 0x0000027FBFA2C8D0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retrieval Chain, Document chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following questions based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    ")\n",
    "document_chain= create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the provided context is incomplete, and I need more information to answer any questions related to it. If you can provide additional context or details, I would be happy to help.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"We can now set up automations to move examples with feedback of some\",\n",
    "    \"context\":[Document(page_content=\"We can now set up automations to move examples with feedback of some\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input---> Retriever -----> vectorstoredb\n",
    "retriever=vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027F8141E850>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following questions based only on the provided context:\\n<context>\\n{context}\\n</context>\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000027FBF7B5B50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000027FBF79E910>, root_client=<openai.OpenAI object at 0x0000027FBF548B90>, root_async_client=<openai.AsyncOpenAI object at 0x0000027FBFA2C8D0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. What is the main objective of the example provided in the context?\\n\\n   The main objective of the example is to build a bot that classifies GitHub issues based on their title and collects user feedback to improve the classifier\\'s performance.\\n\\n2. What is the purpose of setting up automations in the context?\\n\\n   The purpose of setting up automations is to move examples with feedback into a dataset, with one automation for positive feedback and another for negative feedback. This helps in using runs with positive feedback as good examples for future iterations.\\n\\n3. What dataset is mentioned for storing data with positive feedback?\\n\\n   The dataset mentioned for storing data with positive feedback is called \"classifier-github-issues.\"\\n\\n4. What environment variable is set to send all traces to a specific project?\\n\\n   The environment variable set to send all traces to a specific project is \"LANGCHAIN_PROJECT,\" with the value \"classifier.\"'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the response from llm\n",
    "response=retrieval_chain.invoke({\"input\":\"We can now set up automations to move examples with feedback of some\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'We can now set up automations to move examples with feedback of some',\n",
       " 'context': [Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='In this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automationsâ€‹\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.'),\n",
       "  Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then use that in the application'),\n",
       "  Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='Update the applicationâ€‹\\nWe can now update our code to pull down the dataset we are sending runs to.\\nOnce we pull it down, we can create a string with the examples in it.\\nWe can then put this string as part of the prompt!'),\n",
       "  Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='That is exactly what we will do in this example.\\nThe objectiveâ€‹\\nIn this example, we will build a bot that classify GitHub issues based on their title.\\nIt will take in a title and classify it into one of many different classes.\\nThen, we will start to collect user feedback and use that to shape how this classifier performs.\\nGetting startedâ€‹\\nTo get started, we will first set it up so that we send all traces to a specific project.\\nWe can do this by setting an environment variable:\\nimport osos.environ[\"LANGCHAIN_PROJECT\"] = \"classifier\"\\nWe can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.')],\n",
       " 'answer': '1. What is the main objective of the example provided in the context?\\n\\n   The main objective of the example is to build a bot that classifies GitHub issues based on their title and collects user feedback to improve the classifier\\'s performance.\\n\\n2. What is the purpose of setting up automations in the context?\\n\\n   The purpose of setting up automations is to move examples with feedback into a dataset, with one automation for positive feedback and another for negative feedback. This helps in using runs with positive feedback as good examples for future iterations.\\n\\n3. What dataset is mentioned for storing data with positive feedback?\\n\\n   The dataset mentioned for storing data with positive feedback is called \"classifier-github-issues.\"\\n\\n4. What environment variable is set to send all traces to a specific project?\\n\\n   The environment variable set to send all traces to a specific project is \"LANGCHAIN_PROJECT,\" with the value \"classifier.\"'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
